{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_row(row):\n",
    "    # Normalize a row by removing BOM and trimming whitespace\n",
    "    return [cell.strip().lstrip('\\ufeff').lstrip('\\uFEFF') for cell in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_csv(file1, file2):\n",
    "    with open(file1, 'r', newline='', encoding='utf-8-sig') as f1, open(file2, 'r', newline='', encoding='utf-8-sig') as f2:\n",
    "        reader1 = csv.reader(f1)\n",
    "        reader2 = csv.reader(f2)\n",
    "        \n",
    "        row_index = 1  # Initialize row counter (assuming 1-based indexing for readability)\n",
    "        \n",
    "        for row1, row2 in zip(reader1, reader2):\n",
    "            # Normalize and compare rows\n",
    "            normalized_row1 = normalize_row(row1)\n",
    "            normalized_row2 = normalize_row(row2)\n",
    "            if normalized_row1 != normalized_row2:\n",
    "                print(f\"Row {row_index} is different: {normalized_row1} vs {normalized_row2}\")\n",
    "                return\n",
    "            \n",
    "            row_index += 1  # Increment the row counter\n",
    "        \n",
    "        # Check if any file has more rows left\n",
    "        try:\n",
    "            next(reader1)\n",
    "            print(\"The files are not exactly equal. Additional rows found in the first file.\")\n",
    "            return\n",
    "        except StopIteration:\n",
    "            try:\n",
    "                next(reader2)\n",
    "                print(\"The files are not exactly equal. Additional rows found in the second file.\")\n",
    "                return\n",
    "            except StopIteration:\n",
    "                pass  # Both files have been fully read and are equal so far\n",
    "\n",
    "    print(\"The files are exactly equal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the files, they correspond to the default configuration ML experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files are exactly equal.\n"
     ]
    }
   ],
   "source": [
    "file1 = r\"C:/Users/xedua/OneDrive/Escritorio/MCC-I/Research/Thesis_Confirmatory_Experiments/Results/PHERMES_results/comparison_default_static.csv\"\n",
    "file2 = r\"C:/Users/xedua/OneDrive/Escritorio/MCC-I/Research/Thesis_Confirmatory_Experiments/Results/PHERMES_results/results_retrieved_6_mar_24_bayliss_whats/comparison_static.csv\"\n",
    "compare_csv(file1, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files are exactly equal.\n"
     ]
    }
   ],
   "source": [
    "file1 = r\"C:/Users/xedua/OneDrive/Escritorio/MCC-I/Research/Thesis_Confirmatory_Experiments/Results/PHERMES_results/comparison_default_dynamic.csv\"\n",
    "file2 = r\"C:/Users/xedua/OneDrive/Escritorio/MCC-I/Research/Thesis_Confirmatory_Experiments/Results/PHERMES_results/results_retrieved_6_mar_24_bayliss_whats/comparison_dynamic.csv\"\n",
    "compare_csv(file1, file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the files, they correspond to the custom configuration ML experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files are exactly equal.\n"
     ]
    }
   ],
   "source": [
    "file1 = r\"C:/Users/xedua/OneDrive/Escritorio/MCC-I/Research/Thesis_Confirmatory_Experiments/Results/PHERMES_results/comparison_custom_static.csv\"\n",
    "file2 = r\"C:\\Users\\xedua\\OneDrive\\Escritorio\\MCC-I\\Research\\Thesis_Confirmatory_Experiments\\Results\\PHERMES_results\\results_me_whats_sent-17_feb_24_conference\\comparison_static.csv\"\n",
    "compare_csv(file1, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files are exactly equal.\n"
     ]
    }
   ],
   "source": [
    "file1 = r\"C:/Users/xedua/OneDrive/Escritorio/MCC-I/Research/Thesis_Confirmatory_Experiments/Results/PHERMES_results/comparison_custom_dynamic.csv\"\n",
    "file2 = r\"C:\\Users\\xedua\\OneDrive\\Escritorio\\MCC-I\\Research\\Thesis_Confirmatory_Experiments\\Results\\PHERMES_results\\results_me_whats_sent-17_feb_24_conference/comparison_dynamic.csv\"\n",
    "compare_csv(file1, file2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
